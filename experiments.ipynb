{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVQGJ01kjzDL",
        "colab_type": "text"
      },
      "source": [
        "## Loading dataset\n",
        "The RuTweetCorp dataset was presented in Y. Rubtsova, \"Constructing a Corpus for Sentiment Classification Training\", Software & Systems, vol. 109, no. 1, pp. 72-78, 2015 and is available at http://study.mokoron.com."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V68qOA7mjX94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "e206257c-d0f0-4c23-84c2-689a85efeb78"
      },
      "source": [
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-31 20:42:00--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.1, 2620:100:6030:1::a27d:5001\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2020-05-31 20:42:01--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com/cd/0/inline/A4wumffcHqTga7w2m9tGUOXk0Fmj36ukIkLsdld8ZDzBeIc7TdwKB9CheXV_fLPvAJc-Szg6x1LIBinFlYXz1KLSgf9IZRuauWEYlQNCC6uNXw/file# [following]\n",
            "--2020-05-31 20:42:01--  https://uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com/cd/0/inline/A4wumffcHqTga7w2m9tGUOXk0Fmj36ukIkLsdld8ZDzBeIc7TdwKB9CheXV_fLPvAJc-Szg6x1LIBinFlYXz1KLSgf9IZRuauWEYlQNCC6uNXw/file\n",
            "Resolving uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com (uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com)... 162.125.80.6, 2620:100:6030:6::a27d:5006\n",
            "Connecting to uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com (uc3e8b35c480988f437db44d83df.dl.dropboxusercontent.com)|162.125.80.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv.2’\n",
            "\n",
            "negative.csv.2      100%[===================>]  23.32M  24.5MB/s    in 1.0s    \n",
            "\n",
            "2020-05-31 20:42:03 (24.5 MB/s) - ‘negative.csv.2’ saved [24450101/24450101]\n",
            "\n",
            "--2020-05-31 20:42:04--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.1, 2620:100:6030:1::a27d:5001\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2020-05-31 20:42:04--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com/cd/0/inline/A4zZPPOd0hbq6D2WTPgZdcN89E1R2cqbtHZH2bk4jC8sJfdEHqCmGQPlVlCq3-CbfjV0KlRiz06aTDPao4tP6HTt87SoRfS_rQbG_Hl7ifZMFA/file# [following]\n",
            "--2020-05-31 20:42:05--  https://ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com/cd/0/inline/A4zZPPOd0hbq6D2WTPgZdcN89E1R2cqbtHZH2bk4jC8sJfdEHqCmGQPlVlCq3-CbfjV0KlRiz06aTDPao4tP6HTt87SoRfS_rQbG_Hl7ifZMFA/file\n",
            "Resolving ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com (ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6030:6::a27d:5006\n",
            "Connecting to ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com (ucd17714606548032df0fc6b97d5.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv.2’\n",
            "\n",
            "positive.csv.2      100%[===================>]  25.02M  42.7MB/s    in 0.6s    \n",
            "\n",
            "2020-05-31 20:42:06 (42.7 MB/s) - ‘positive.csv.2’ saved [26233379/26233379]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPmb1p6NlExg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuT6ynsQlQmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "960826c1-620a-42ff-bd98-31c208eac831"
      },
      "source": [
        "df = pd.concat((pd.read_csv(f, sep=';', header=None) for f in ['positive.csv', 'negative.csv']), ignore_index=True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>408906692374446080</td>\n",
              "      <td>1386325927</td>\n",
              "      <td>pleease_shut_up</td>\n",
              "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7569</td>\n",
              "      <td>62</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>408906692693221377</td>\n",
              "      <td>1386325927</td>\n",
              "      <td>alinakirpicheva</td>\n",
              "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11825</td>\n",
              "      <td>59</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>408906695083954177</td>\n",
              "      <td>1386325927</td>\n",
              "      <td>EvgeshaRe</td>\n",
              "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1273</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>408906695356973056</td>\n",
              "      <td>1386325927</td>\n",
              "      <td>ikonnikova_21</td>\n",
              "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1549</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>408906761416867842</td>\n",
              "      <td>1386325943</td>\n",
              "      <td>JumpyAlex</td>\n",
              "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>597</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0           1                2   ...  9   10  11\n",
              "0  408906692374446080  1386325927  pleease_shut_up  ...  62  61   0\n",
              "1  408906692693221377  1386325927  alinakirpicheva  ...  59  31   2\n",
              "2  408906695083954177  1386325927        EvgeshaRe  ...  26  27   0\n",
              "3  408906695356973056  1386325927    ikonnikova_21  ...  19  17   0\n",
              "4  408906761416867842  1386325943        JumpyAlex  ...  16  23   1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaVljnpIlbXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "f7d38f25-a5c6-41fd-f127-0581438c1635"
      },
      "source": [
        "df = df.drop(columns=[0,1,2,5,6,7,8,9,10,11])\n",
        "df.columns=['text','target']\n",
        "df.head(2), df.tail(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                text  target\n",
              " 0  @first_timee хоть я и школота, но поверь, у на...       1\n",
              " 1  Да, все-таки он немного похож на него. Но мой ...       1,\n",
              "                                                      text  target\n",
              " 226832  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...      -1\n",
              " 226833  Такси везет меня на работу. Раздумываю приплат...      -1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il1fqFzgl1ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "8ae9df12-66a0-4bb7-a11b-9e2213104151"
      },
      "source": [
        "df.target = df.target.map({-1:0, 1:1})\n",
        "y = df.target.values\n",
        "len(df), df.groupby(['target']).target.count(), df.groupby(['target']).target.count()/len(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(226834, target\n",
              " 0    111923\n",
              " 1    114911\n",
              " Name: target, dtype: int64, target\n",
              " 0    0.493414\n",
              " 1    0.506586\n",
              " Name: target, dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnBJI7Mamzdh",
        "colab_type": "text"
      },
      "source": [
        "## Baseline\n",
        "TF-IDF + Logistic regression with default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4poHq2mwvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igNbkzGImPLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ad2e76f3-06a4-496c-92bc-3db46d6740fc"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "x = vectorizer.fit_transform(df.text)\n",
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(226834, 294600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au1OoM9tnufI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "509a1a1f-15cf-46e2-d037-5a112b3dc658"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
        "clf = LogisticRegression()\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(f1_score(y_pred, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7690796714926763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Z1_u0wnOZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "52bbef91-7ba2-454c-9e05-099078a164df"
      },
      "source": [
        "f1_scores = []\n",
        "for seed in np.random.randint(1000, size=(5)):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=seed)\n",
        "    clf = LogisticRegression(\n",
        "                          random_state=42, \n",
        "                          solver = 'saga', \n",
        "                          max_iter = 1000,\n",
        "                          verbose=0,\n",
        "                          )\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    print('  ', f1_score(y_pred, y_test))\n",
        "    f1_scores += [f1_score(y_pred, y_test)]\n",
        "\n",
        "print('TF-IDF LR baseline f1-score:', np.round(np.mean(f1_scores),3),'\\xB1' ,np.round(np.std(f1_scores),3))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0.7705563345778919\n",
            "   0.7648230013835927\n",
            "   0.7705309509695994\n",
            "   0.7693922464872185\n",
            "   0.7692567567567568\n",
            "TF-IDF LR baseline f1-score: 0.769 ± 0.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRCywC3Iy6pX",
        "colab_type": "text"
      },
      "source": [
        "##Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3maZ1pdqGbl",
        "colab_type": "code",
        "outputId": "ef01c501-cb84-4ee6-e442-225ef40c4002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "scores = []\n",
        "for C in [0.01,0.1,0.5,1,5,10,100]:\n",
        "    f1_scores = []\n",
        "    print('C:', C)\n",
        "    for seed in np.random.randint(1000, size=(5)):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=seed)\n",
        "        clf = LogisticRegression(\n",
        "                              C=C,\n",
        "                              random_state=42, \n",
        "                              solver = 'saga', \n",
        "                              max_iter = 1000,\n",
        "                              verbose=0,\n",
        "                              )\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "        print('  ', f1_score(y_pred, y_test))\n",
        "        f1_scores += [f1_score(y_pred, y_test)]\n",
        "    print('F1 score:', np.round(np.mean(f1_scores),3),'\\xB1' ,np.round(np.std(f1_scores),3))\n",
        "    scores += [(C, np.mean(f1_scores),np.std(f1_scores))]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C: 0.01\n",
            "   0.693670388683323\n",
            "   0.6945687634223513\n",
            "   0.6945929107781094\n",
            "   0.6949291256097161\n",
            "   0.6937564541773895\n",
            "F1 score: 0.694 ± 0.0\n",
            "C: 0.1\n",
            "   0.7368280512024565\n",
            "   0.7316740652069097\n",
            "   0.7323295482967336\n",
            "   0.7365732316065375\n",
            "   0.7368438588015792\n",
            "F1 score: 0.735 ± 0.002\n",
            "C: 0.5\n",
            "   0.7642816410049982\n",
            "   0.7632759027613877\n",
            "   0.7641210495431302\n",
            "   0.763571620532115\n",
            "   0.76195242384813\n",
            "F1 score: 0.763 ± 0.001\n",
            "C: 1\n",
            "   0.7668255416962445\n",
            "   0.7666972570612829\n",
            "   0.7727103939506464\n",
            "   0.7679401965261218\n",
            "   0.7708055785089124\n",
            "F1 score: 0.769 ± 0.002\n",
            "C: 5\n",
            "   0.7752841737102885\n",
            "   0.7718871094955592\n",
            "   0.7740799617113651\n",
            "   0.7752830028087496\n",
            "   0.7698640004116003\n",
            "F1 score: 0.773 ± 0.002\n",
            "C: 10\n",
            "   0.7686231411203077\n",
            "   0.7683050179150024\n",
            "   0.7705259533442369\n",
            "   0.765165663692329\n",
            "   0.7654180855088915\n",
            "F1 score: 0.768 ± 0.002\n",
            "C: 100\n",
            "   0.7503626671327449\n",
            "   0.7488362398388105\n",
            "   0.7453335668009105\n",
            "   0.7475110909281448\n",
            "   0.749751269832958\n",
            "F1 score: 0.748 ± 0.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpGEMP8dZYwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "5f66548f-f4e7-490f-c48a-52fab78ec377"
      },
      "source": [
        "for i in sorted(scores, key=lambda x: x[1])[::-1]:\n",
        "    print(i[:2])\n",
        "best_C = sorted(scores, key=lambda x: x[1])[-1][0]\n",
        "print('Best C LR hyperparemeter:', best_C)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 0.7732796496275125)\n",
            "(1, 0.7689957935486416)\n",
            "(10, 0.7676075723161534)\n",
            "(0.5, 0.7634405275379523)\n",
            "(100, 0.7483589669067138)\n",
            "(0.1, 0.7348497510228433)\n",
            "(0.01, 0.6943035285341779)\n",
            "Best C LR hyperparemeter: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqTVFIBGAWTP",
        "colab_type": "text"
      },
      "source": [
        "## Word N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeD6hmi5zGDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "63605f2d-5d57-4c73-e396-832084a851a4"
      },
      "source": [
        "for word_ngram in [1,2,3]:\n",
        "    print('Number of word N-grams:', word_ngram)\n",
        "    f1_scores = []\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        ngram_range=(1,word_ngram),\n",
        "    )\n",
        "    x = vectorizer.fit_transform(df.text)\n",
        "\n",
        "    for seed in np.random.randint(1000, size=(5)):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=seed)\n",
        "        clf = LogisticRegression(\n",
        "                              C=best_C,\n",
        "                              random_state=42, \n",
        "                              solver = 'saga', \n",
        "                              max_iter = 1000,\n",
        "                              verbose=0,\n",
        "                              )\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "        print(' ', f1_score(y_pred, y_test))\n",
        "        f1_scores += [f1_score(y_pred, y_test)]\n",
        "    print('F1 score:', np.round(np.mean(f1_scores),3),'\\xB1' ,np.round(np.std(f1_scores),3))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of word N-grams: 1\n",
            "  0.7759486321254141\n",
            "  0.7740300654042394\n",
            "  0.7736249443816955\n",
            "  0.7734346910473059\n",
            "  0.771822200897906\n",
            "F1 score: 0.774 ± 0.001\n",
            "Number of word N-grams: 2\n",
            "  0.7871075166508089\n",
            "  0.7875730127825277\n",
            "  0.7898236092265943\n",
            "  0.7885468522469438\n",
            "  0.7888347031340585\n",
            "F1 score: 0.788 ± 0.001\n",
            "Number of word N-grams: 3\n",
            "  0.786294750713815\n",
            "  0.7880454031809213\n",
            "  0.7906647807637907\n",
            "  0.7850919487726065\n",
            "  0.7864902365562286\n",
            "F1 score: 0.787 ± 0.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPPJibVcTsg9",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOMfV-GEBEwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "4ae7003e-c2d7-460e-f46f-0de6052209c1"
      },
      "source": [
        "np.random.choice(df.text.values,30)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@bulygin499 действительно неуч. Алексей Булыгин внес больший вклад в изучение истории, чем профессор Йельского университета)',\n",
              "       'Всего одну ночь не было столько всего пропустила(((',\n",
              "       'Оказывается, даже в государственных учереждениях есть добрые понимающие люди)',\n",
              "       '@_nat_borisova_ у вас тоже пофоткали его с ректором и повесят во всех корпусах лет на 20?)',\n",
              "       'И кто теперь первый в заветном списке?\\nА вот Евгеша теперь первая :D\\n:З',\n",
              "       '@owl_bazzinga ну мне тот больше выпуск нравится))особенно рок-н-рольщик!))ну он везде хорош)',\n",
              "       'Не плаааачь \\n\"@ZazEAGLE: БРО УЕЗЖАЕТ:((((((((\"',\n",
              "       '@Maria__Way твой последний выпуск был просто великолепен, так что, да, я твоя поклонница:D http://t.co/OrTxAGEJtc',\n",
              "       'Кстати. Если я поел — все, я не работник :( думать не але, писать код — не але. Могу читать ньюсы, фтыкать и играть во чт',\n",
              "       'RT @ruslp: в этом весь Ваня)\\n#NoizeMC #нойзерфолловьнойзера http://t.co/pbQ7as70T5',\n",
              "       '@naaaaaaaska пхахаха,вот фак!!\\nу меня теперь тоже не работает !\\n(((((((((',\n",
              "       'RT @julieka_83: Почему я такая \"здоровая\"?? Столько планов и дел было!и что теперь? Я лежу в кровати и ничего сделать не могу(',\n",
              "       'Расстраивает тенденция, что раз за разом все скучнее. Прекрасна только рубашка Курта с лисой, грустный Блейни:( и Броуди.',\n",
              "       '#интересно Что-то левая рука отнимается в последнее времянадо б к докторам сходить:((',\n",
              "       'RT @sponge_hi: @metnikova бывает.надеюсь,у тебя все очень скоро наладиться и будет хорошо)))с:',\n",
              "       'Эх, Ризванова :(\\nНе реви только, со всеми бывает',\n",
              "       'запостил результаты своего ковыряния в ядре в ЖЖ ( (',\n",
              "       'Утро добрым не бывает,ноготь сломала(((аааааааааа',\n",
              "       '@lubasha_walle художественное падание со стремянки? однако ты аккуратней там :-(',\n",
              "       'одни звонками портят настроение, другие наоборот поднимают ;-)',\n",
              "       'Бывшая однокласница вспомнила, предложила поехать отдыхать на 10 дней буду думать)',\n",
              "       'Поддерживать переписки я не люблю ну щас не люблю ranwe to ya Lubil daadadaa )))0)',\n",
              "       'Каждый должен отвечать за свои дела, темные делишки всегда раскроются) http://t.co/4NS0mnjH10',\n",
              "       'Капец город!!! Даже стоя на остановке умудрился поймать чью-то сеть wifi)))',\n",
              "       '@tomson000 @r2p3r0k он когда в капюшоне читает, и голос сделает как в \"поднебесная дурка\" - я теряю бошку :D',\n",
              "       'мне многие кто нравятся это незначит чть я с ними хочу встречатся Таань как ты это понять не можешь (',\n",
              "       'Все что угодно, лишь бы не экзамены, полит география и теория!( #exams #politicalscience #study… http://t.co/FUCrPNlNeg',\n",
              "       '@Strange_eternal может, я не заметила... Если они вставляют какие-то намеки, это не просто так. И я не представляю, как ждать два года(',\n",
              "       '@ivan_zhidkov печально, я думал, у него получится закрепиться в Европе( если отвалятся обратно и Амини с Рохасом, в А-Лигу долго не полезут.',\n",
              "       'Фильм был просто офигенный) В основном, конечно, из-за Паши :З'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swRUuZxqBEpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "replaces = [\n",
        " ['[:;][(]+',' <NSMILE> '],\n",
        " ['[:;]-[(]+',' <NSMILE> '],\n",
        " ['\\([(]+',' <NSMILE> '], \n",
        " ['[:;][)]+',' <PSMILE> '], \n",
        " ['[:;]-[)]+',' <PSMILE> '], \n",
        " ['\\)[)]+',' <PSMILE> '], \n",
        " ['@[_*:,А-Я,а-я,A-Z,a-z,0-9]+\\s',' <UNAME> '],\n",
        " ['http:[\\.,/,0-9,a-z,A-Z]+[\\s|$]?', ' <HTTP> '] \n",
        "]\n",
        "\n",
        "def add_tokens(s):\n",
        "    for l, r in replaces:\n",
        "        s = re.sub(l, r, s)\n",
        "    return s "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6NIMtJdUL8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "48b16b36-7b16-4c9f-db5c-fce8dc52bda2"
      },
      "source": [
        "df.iloc[813].text, add_tokens(df.iloc[813].text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Счастливый обладатель iphone 5c :-) http://t.co/YqZnfGr4yK',\n",
              " 'Счастливый обладатель iphone 5c  <PSMILE>   <HTTP> ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcPRHac7UZsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "890aab12-b740-4f2c-9607-52fde1987865"
      },
      "source": [
        "df.iloc[224032].text, add_tokens(df.iloc[224032].text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('@meow_Julia_1D_  Всё равно, я переживаю :((',\n",
              " ' <UNAME>  Всё равно, я переживаю  <NSMILE> ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZxnKBLOBEiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text_with_tokens'] = df.text.apply(add_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP_zsMK-BSsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "136c33fc-45fe-43f0-b939-7d815b84e2a2"
      },
      "source": [
        "for word_ngram in [1,2,3]:\n",
        "    print('Number of word N-grams:', word_ngram)\n",
        "    f1_scores = []\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        ngram_range=(1,word_ngram),\n",
        "    )\n",
        "    x = vectorizer.fit_transform(df.text_with_tokens)\n",
        "\n",
        "    for seed in np.random.randint(1000, size=(5)):\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=seed)\n",
        "        clf = LogisticRegression(\n",
        "                              C=best_C,\n",
        "                              random_state=42, \n",
        "                              solver = 'saga', \n",
        "                              max_iter = 100,\n",
        "                              verbose=0,\n",
        "                              )\n",
        "        clf.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "        print(' ', f1_score(y_pred, y_test))\n",
        "        f1_scores += [f1_score(y_pred, y_test)]\n",
        "    print('F1 score:', np.round(np.mean(f1_scores),3),'\\xB1' ,np.round(np.std(f1_scores),3))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of word N-grams: 1\n",
            "  0.894570418843741\n",
            "  0.8940512227475257\n",
            "  0.8938711969948222\n",
            "  0.8934290260333797\n",
            "  0.891794470704254\n",
            "F1 score: 0.894 ± 0.001\n",
            "Number of word N-grams: 2\n",
            "  0.9001922622862347\n",
            "  0.9002960172228203\n",
            "  0.9010826440723555\n",
            "  0.9023351003153729\n",
            "  0.901914520695699\n",
            "F1 score: 0.901 ± 0.001\n",
            "Number of word N-grams: 3\n",
            "  0.9011509591326106\n",
            "  0.8990746288529392\n",
            "  0.9010912003203524\n",
            "  0.9036575823663575\n",
            "  0.9006014032743067\n",
            "F1 score: 0.901 ± 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}